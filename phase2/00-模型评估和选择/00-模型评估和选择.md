# 模型评估与选择

## 1. 经验误差与过拟合

+ 学习器的实际预测输出与样本的真实输出之间的差异称为"误差" (error) ,
+ 学习器在训练集上的误差称为"训练误差" (training error)或"**经验误差**" (empirical error) 
+ 在新样本上的误差称为"泛化误差" (generalizationerror).

+ 应该从训练样本中尽可能学出适用于所有潜在样本的"普遍规律"
+ 当学习器把训练样本学得"太好"了的时候，很可能巳经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降这种现象在机器学习中称为**"过拟合"** (overfitting). 
+ 与"过拟合"相对的是**"欠拟合"** (underfitting) ，这是指对训练样本的一般性质尚未学好.

## 2. 评估方法

+ 可通过**实验测试**来对学习器的**泛化误差**进行**评估**并进而做出选择
+ 为此， 需使用一个"**测试集**" (testing set)来测试学习器对新样本的判别能力，然后以测试集上的"测试误差" (testing error)作为泛化误差的近似

### 2.1 留出法

+ "留出法" (hold-out)直接将数据集D **划分为两个互斥的集合**，其中一个集合作为训练集S，另一个作为测试集T。在S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计.
+ 训练/测试集的划分要尽可能保持**数据分布的一致性**，避免困数据划分过程引入额外的偏差而对最终结果产生影响。

### 2.2 交叉验证法

 